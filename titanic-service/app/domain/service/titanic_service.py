import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from app.domain.model.titanic_schema import TitanicSchema

"""
PassengerId  ê³ ê°ID,
Survived ìƒì¡´ì—¬ë¶€,
Pclass ìŠ¹ì„ ê¶Œ 1 = 1ë“±ì„, 2 = 2ë“±ì„, 3 = 3ë“±ì„,
Name,
Sex,
Age,
SibSp ë™ë°˜í•œ í˜•ì œ, ìë§¤, ë°°ìš°ì,
Parch ë™ë°˜í•œ ë¶€ëª¨, ìì‹,
Ticket í‹°ì¼“ë²ˆí˜¸,
Fare ìš”ê¸ˆ,
Cabin ê°ì‹¤ë²ˆí˜¸,
Embarked ìŠ¹ì„ í•œ í•­êµ¬ëª… C = ì‰ë¸Œë£¨, Q = í€¸ì¦ˆíƒ€ìš´, S = ì‚¬ìš°ìŠ¤í–„íŠ¼
"""

class TitanicService:
    def __init__(self, data_dir: str = './app/store/'):
        self.dataset = TitanicSchema(
            context=data_dir,
            fname='',
            train=None,
            test=None,
            id='',
            label=''
        )

    def new_model(self, fname: str) -> pd.DataFrame:
        path = Path(self.dataset.context) / fname
        return pd.read_csv(path)

    def preprocess(self, train_fname: str, test_fname: str) -> TitanicSchema:
        print("-------- ëª¨ë¸ ì „ì²˜ë¦¬ ì‹œì‘ --------")
        ds = self.dataset
        ds.train = self.new_model(train_fname)
        ds.test = self.new_model(test_fname)
        ds.id = ds.test['PassengerId']
        ds.label = ds.train['Survived']
        ds.train = ds.train.drop('Survived', axis=1)

        ds = self.drop_feature(ds, 'SibSp', 'Parch', 'Cabin', 'Ticket')
        ds = self.extract_title_from_name(ds)
        title_mapping = self.remove_duplicate_title(ds)
        ds = self.title_nominal(ds, title_mapping)
        ds = self.drop_feature(ds, 'Name')
        ds = self.gender_nominal(ds)
        ds = self.drop_feature(ds, 'Sex')
        ds = self.embarked_nominal(ds)
        ds = self.age_ratio(ds)
        ds = self.drop_feature(ds, 'Age')
        ds = self.pclass_ordinal(ds)
        ds = self.fare_ordinal(ds)
        ds = self.drop_feature(ds, 'Fare')

        return ds

    def drop_feature(self, dataset: TitanicSchema, *features: str) -> TitanicSchema:
        for col in features:
            dataset.train.drop(columns=col, inplace=True)
            dataset.test.drop(columns=col, inplace=True)
        return dataset

    def extract_title_from_name(self, dataset: TitanicSchema) -> TitanicSchema:
        for df in [dataset.train, dataset.test]:
            df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)
        return dataset

    def remove_duplicate_title(self, dataset: TitanicSchema) -> dict:
        all_titles = set(dataset.train['Title'].unique()) | set(dataset.test['Title'].unique())
        print(f"ğŸ“Œ ì „ì²´ ì§í•¨ ëª©ë¡: {sorted(all_titles)}")
        return {
            'Mr': 1, 'Ms': 2, 'Mrs': 3, 'Master': 4,
            'Royal': 5, 'Rare': 6
        }

    def title_nominal(self, dataset: TitanicSchema, title_mapping: dict) -> TitanicSchema:
        for df in [dataset.train, dataset.test]:
            df['Title'] = df['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')
            df['Title'] = df['Title'].replace(
                ['Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona', 'Mme'], 'Rare')
            df['Title'] = df['Title'].replace({'Mlle': 'Mr', 'Miss': 'Ms'})
            df['Title'] = df['Title'].map(title_mapping)
        return dataset

    def gender_nominal(self, dataset: TitanicSchema) -> TitanicSchema:
        mapping = {'male': 1, 'female': 2}
        for df in [dataset.train, dataset.test]:
            df['Gender'] = df['Sex'].map(mapping)
        return dataset

    def embarked_nominal(self, dataset: TitanicSchema) -> TitanicSchema:
        mapping = {'S': 1, 'C': 2, 'Q': 3}
        for df in [dataset.train, dataset.test]:
            df['Embarked'] = df['Embarked'].fillna('S')
            df['Embarked'] = df['Embarked'].map(mapping)
        return dataset

    def age_ratio(self, dataset: TitanicSchema) -> TitanicSchema:
        mapping = {'Unknown': 0, 'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4,
                   'Young Adult': 5, 'Adult': 6, 'Senior': 7}
        for df in [dataset.train, dataset.test]:
            df['Age'] = df['Age'].fillna(-1)

        max_age = max(dataset.train['Age'].max(), dataset.test['Age'].max())
        bins = [-1] + [max_age * i / 7 for i in range(1, 8)]
        labels = list(mapping.keys())[1:]  # 'Baby' ~ 'Senior'

        for df in [dataset.train, dataset.test]:
            df['AgeGroup'] = pd.cut(df['Age'], bins=bins, labels=labels, include_lowest=True)
            df['AgeGroup'] = df['AgeGroup'].map(mapping)
        return dataset

    def fare_ordinal(self, dataset: TitanicSchema) -> TitanicSchema:
        mapping = {'Free': 1, 'Lower': 2, 'Mid': 3, 'Premium': 4}
        bins = [0, 0.01, 20, 150, 870]
        labels = list(mapping.keys())

        for df in [dataset.train, dataset.test]:
            df['Fare'] = df['Fare'].fillna(0)
            df['FareGroup'] = pd.cut(df['Fare'], bins=bins, labels=labels, include_lowest=True)
            df['FareGroup'] = df['FareGroup'].map(mapping)
        return dataset

    def pclass_ordinal(self, dataset: TitanicSchema) -> TitanicSchema:
        return dataset

    # ë¨¸ì‹ ëŸ¬ë‹ : learning
    def create_k_fold(self, X, y, n_splits=5):
        return StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)

    def create_random_variable(self):
        X_train = self.dataset.train
        y_train = self.dataset.label
        X_test = self.dataset.test
        return X_train, y_train, X_test
        
    def evaluate_model(self, model_class, X, y, **kwargs):
        """
        ëª¨ë¸ì„ í‰ê°€í•˜ëŠ” ê³µí†µ í•¨ìˆ˜
        
        Args:
            model_class: ì‚¬ìš©í•  ëª¨ë¸ í´ë˜ìŠ¤ (ì˜ˆ: DecisionTreeClassifier)
            X: ì…ë ¥ ë°ì´í„°
            y: íƒ€ê²Ÿ ë ˆì´ë¸”
            **kwargs: ëª¨ë¸ í´ë˜ìŠ¤ì— ì „ë‹¬í•  ì¶”ê°€ ë§¤ê°œë³€ìˆ˜
            
        Returns:
            float: í‰ê·  ì •í™•ë„
        """
        kf = self.create_k_fold(X, y)
        accuracies = []
        
        for train_index, test_index in kf.split(X, y):
            X_fold_train, X_fold_test = X.iloc[train_index], X.iloc[test_index]
            y_fold_train, y_fold_test = y.iloc[train_index], y.iloc[test_index]
            
            model = model_class(**kwargs)
            model.fit(X_fold_train, y_fold_train)
            
            pred = model.predict(X_fold_test)
            accuracies.append(accuracy_score(y_fold_test, pred))
        
        return np.mean(accuracies)

    def accuracy_by_dtree(self, X, y):
        avg_accuracy = self.evaluate_model(DecisionTreeClassifier, X, y, random_state=42)
        print(f"ê²°ì •íŠ¸ë¦¬ í‰ê·  ì •í™•ë„: {avg_accuracy:.4f}")
        return avg_accuracy
    # if-elseì²˜ëŸ¼ ë°ì´í„°ë¥¼ ë¶„í• í•˜ë©° ì¡°ê±´ íŠ¸ë¦¬ë¥¼ ë§Œë“¦ (ì˜ˆ: ì„±ë³„ â†’ ë‚˜ì´ â†’ ê°ì‹¤ë“±ê¸‰).
    # ë°ì´í„°ë¥¼ ê°€ì¥ ì˜ êµ¬ë¶„í•  ìˆ˜ ìˆëŠ” íŠ¹ì„±ë¶€í„° if-elseì²˜ëŸ¼ ë‚˜ëˆ„ë©° ìƒì¡´ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. 
    # íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì—ì„œëŠ” ì„±ë³„, ë“±ê¸‰, ë‚˜ì´ ê°™ì€ ë³€ìˆ˜ë“¤ì´ ì£¼ìš” ë¶„ê¸° ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©
    # í›ˆë ¨ë°ì´í„°ì— ë§ì¶° í•™ìŠµì„ í•˜ë‹¤ë³´ë‹ˆ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ë“¤ì–´ì˜¤ë©´ ì˜ˆì¸¡ ì •í™•ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ (ex. ì—¬ì„±ì´ë©´ ìƒì¡´ìœ¼ë¡œ ì˜ˆì¸¡í•˜ëŠ” ê²½ìš°)

    def accuracy_by_random_forest(self, X, y):
        avg_accuracy = self.evaluate_model(RandomForestClassifier, X, y, random_state=42)
        print(f"ëœë¤í¬ë ˆìŠ¤íŠ¸ í‰ê·  ì •í™•ë„: {avg_accuracy:.4f}")
        return avg_accuracy
    # ì—¬ëŸ¬ ê²°ì •íŠ¸ë¦¬ë¥¼ í•™ìŠµí•œ í›„ ê²°ê³¼ë¥¼ íˆ¬í‘œë¡œ ì¢…í•© (ì•™ìƒë¸”)

    def accuracy_by_naive_bayes(self, X, y):
        avg_accuracy = self.evaluate_model(GaussianNB, X, y)
        print(f"ë‚˜ì´ë¸Œë² ì´ì¦ˆ í‰ê·  ì •í™•ë„: {avg_accuracy:.4f}")
        return avg_accuracy
    # ê° íŠ¹ì„±ì´ ë…ë¦½ì´ë¼ê³  ê°€ì •í•˜ê³  í™•ë¥  ê¸°ë°˜ìœ¼ë¡œ ë¶„ë¥˜

    def accuracy_by_knn(self, X, y):
        avg_accuracy = self.evaluate_model(KNeighborsClassifier, X, y, n_neighbors=5)
        print(f"K-ìµœê·¼ì ‘ì´ì›ƒ í‰ê·  ì •í™•ë„: {avg_accuracy:.4f}")
        return avg_accuracy
    # ìƒˆ ë°ì´í„°ê°€ ì£¼ë³€ ì´ì›ƒ(Kê°œ)ê³¼ ì–¼ë§ˆë‚˜ ê°€ê¹Œìš´ì§€ë¡œ íŒë‹¨

    def accuracy_by_svm(self, X, y):
        avg_accuracy = self.evaluate_model(SVC, X, y, random_state=42)
        print(f"ì„œí¬íŠ¸ë²¡í„°ë¨¸ì‹  í‰ê·  ì •í™•ë„: {avg_accuracy:.4f}")
        return avg_accuracy
    # ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ëŠ” ê°€ì¥ ë„“ì€ ê²½ê³„(ì´ˆí‰ë©´)ë¥¼ ì°¾ì•„ ë¶„ë¥˜

    def find_best_model(self):
        print("ğŸ” ìµœì  ëª¨ë¸ ì„ íƒ ì‹œì‘...")
        X, y, _ = self.create_random_variable()
        
        # ê° ëª¨ë¸ í‰ê°€
        models = {
            "ê²°ì •íŠ¸ë¦¬": self.accuracy_by_dtree,
            "ëœë¤í¬ë ˆìŠ¤íŠ¸": self.accuracy_by_random_forest,
            "ë‚˜ì´ë¸Œë² ì´ì¦ˆ": self.accuracy_by_naive_bayes,
            "K-ìµœê·¼ì ‘ì´ì›ƒ": self.accuracy_by_knn,
            "ì„œí¬íŠ¸ë²¡í„°ë¨¸ì‹ ": self.accuracy_by_svm
        }
        
        results = {}
        for name, func in models.items():
            print(f"\n{name} í‰ê°€ ì¤‘...")
            accuracy = func(X, y)
            results[name] = accuracy
        
        # ì •í™•ë„ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        sorted_results = dict(sorted(results.items(), key=lambda x: x[1], reverse=True))
        
        print("\nğŸ“Š ëª¨ë¸ ì •í™•ë„ ìˆœìœ„:")
        for i, (name, accuracy) in enumerate(sorted_results.items(), 1):
            print(f"{i}ìœ„: {name} - {accuracy:.4f}")
        
        best_model = list(sorted_results.keys())[0]
        best_accuracy = sorted_results[best_model]
        
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model} (ì •í™•ë„: {best_accuracy:.4f})")
        return best_model, best_accuracy
    
    
    
    
    